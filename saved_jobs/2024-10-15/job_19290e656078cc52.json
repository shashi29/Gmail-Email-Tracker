[
    {
        "company": "Tanisha Systems Inc",
        "job_title": "AWS Pyspark with Python",
        "location": "Plano, TX, USA",
        "full_location": {
            "city": "Plano",
            "state": "TX",
            "country": "USA"
        },
        "job_details": {
            "employment_type": [
                "contract",
                "full-time",
                "third party"
            ],
            "experience_required": "12+ Years",
            "degree_required": "Bachelor\u2019s Degree in Computer Science/Programming or similar is preferred",
            "visa_sponsorship": "Not specified",
            "notice_period": "Not specified",
            "duration": "Not specified",
            "rate": "Not specified"
        },
        "skills": {
            "core": [
                "Python",
                "SQL",
                "Spark",
                "AWS"
            ],
            "primary": [
                "Data Engineering",
                "Data Pipelines",
                "Communication Skills",
                "Analytical Skills",
                "Problem Solving"
            ],
            "secondary": [
                "Terraform",
                "Cloud Certification",
                "Hudi",
                "Iceberg",
                "Delta Lake",
                "Data Observability",
                "Data Governance",
                "Java",
                "Go",
                "DevOps Tools",
                "Infrastructure-as-Code",
                "Event-driven Architectures",
                "Apache Kafka",
                "Logging Tools",
                "Monitoring Tools",
                "Automation"
            ],
            "all": [
                "Python",
                "SQL",
                "Spark",
                "AWS",
                "Data Engineering",
                "Data Pipelines",
                "Communication Skills",
                "Analytical Skills",
                "Problem Solving",
                "Terraform",
                "Cloud Certification",
                "Hudi",
                "Iceberg",
                "Delta Lake",
                "Data Observability",
                "Data Governance",
                "Java",
                "Go",
                "DevOps Tools",
                "Infrastructure-as-Code",
                "Event-driven Architectures",
                "Apache Kafka",
                "Logging Tools",
                "Monitoring Tools",
                "Automation"
            ]
        },
        "job_type": [
            "onsite"
        ],
        "contact_person": "Rishav Verma",
        "email": "rishav.verma@tanishasystems.com",
        "jd": "From: Rishav Verma, Tanisha Systems Inc rishav.verma@tanishasystems.com Reply to: rishav.verma@tanishasystems.com Greetings,My name is Rishav and I'm an IT recruiter at Tanisha Systems Our records show that you are an experienced IT professional with experience in AWS Pyspark with Python. This experience is relevant to one of my current openings. The opening requires good communication skills in addition to the above skills. It is in Plano TX / Wilmington DE (5 Days Onsite \u2013 No Remote)Job Type :: Contract/FulltimeJob Title:- AWS Pyspark with PythonJob Location:- Plano TX / Wilmington DE (5 Days Onsite \u2013 No Remote)Experience: 12+ Years & Locals Only Note: In-person Interview is mandatory Job Description:Duties and responsibilitiesMandatory Skills:5+ years of experience in a data engineering positionProficiency is Python (or similar) and SQLStrong experience building data pipelines with SparkStrong verbal & written communicationStrong analytical and problem solving skillsExperience with relational datastores, NoSQL datastores and cloud object storesExperience building data processing infrastructure in AWSBonus: Experience with infrastructure as code solutions, preferably TerraformBonus: Cloud certificationBonus: Production experience with ACID compliant formats such as Hudi, Iceberg orDelta LakeBonus: Familiar with data observability solutions, data governance frameworksRequirementsBachelor\u2019s Degree in Computer Science/Programming or similar is preferredRight to workMust have legal right to work in the USA Job responsibilitiesRequired qualifications, capabilities, and skillsFormal training or certification on software engineering concepts and 10+ years applied experienceHands-on practical experience delivering system design, application development, testing, and operational stabilityAdvanced in one or more programming language(s) - Java, Python, GoA strong understanding of business technology drivers and their impact on architecture design, performance and monitoring, best practicesDesign and building web environments on AWS, which includes working with services like EC2, ALB, NLB, Aurora Postgres, DynamoDB, EKS, ECS fargate, MFTS, SQS/SNS, S3 and Route53Advanced in modern technologies such as: Java version 8+, Spring Boot, Restful Microservices, AWS or Cloud Foundry, Kubernetes.Experience using DevOps tools in a cloud environment, such as Ansible, Artifactory, Docker, GitHub, Jenkins, Kubernetes, Maven, and Sonar QubeExperience and knowledge of writing Infrastructure-as-Code (IaC) and Environment-as-Code (EaC), using tools like CloudFormation or TerraformExperience with high volume, SLA critical applications, and building upon messaging and or event-driven architecturesDeep understanding of financial industry and their IT systemsPreferred qualifications, capabilities, and skillsExpert in one or more programming language(s) preferably JavaAWS Associate level certification in Developer, Solutions Architect or DevOpsExperience in building the AWS infrastructure like EKS, EC2, ECS, S3, DynamoDB, RDS, MFTS, Route53, ALB, NLBExperience with high volume, mission critical applications, and building upon messaging and or event-driven architectures using Apache KafkaExperience with logging, observability and monitoring tools including Splunk, Datadog, Dynatrace. CloudWatch or GrafanaExperience in automation and continuous delivery methods using Shell scripts, Gradle, Maven, Jenkins, SpinnakerExperience with microservices architecture, high volume, SLA critical applications and their interdependencies with other applications, microservices and databasesExperience developing process, tooling, and methods to help improve operational maturityThanks & Regards Rishav VermaSr. Technical RecruiterTanisha Systems Inc.[99 Wood Ave South Suite # 308, Iselin, NJ 08830]Office Number: 732-490-4608 | Ext: 429Email: rishav.verma@tanishasystems.comLinkedIn: https://www.linkedin.com/in/rishav-verma-93783b172/Web: www.tanishasystems.com",
        "source": "Email",
        "date_posted": "2024-10-15 10:22:12-05:00",
        "unique_id": "19290e656078cc52",
        "emp_type": [
            "contract",
            "full-time",
            "third party"
        ],
        "tag": "AWS Data Engineer"
    }
]