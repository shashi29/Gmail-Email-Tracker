[
    {
        "company": "Tanisha Systems Inc",
        "job_title": "Analytics - Snowflake and Hadoop - Senior Role",
        "location": "Wilmington, DE, USA",
        "full_location": {
            "city": "Wilmington",
            "state": "DE",
            "country": "USA"
        },
        "job_details": {
            "employment_type": [
                "contract",
                "third party"
            ],
            "experience_required": "10+ years",
            "degree_required": "BS. or MS. in computer science, information systems, math, business, or engineering",
            "visa_sponsorship": "Not specified",
            "notice_period": "Not specified",
            "duration": "Not specified",
            "rate": "Not specified"
        },
        "skills": {
            "core": [
                "Snowflake",
                "Hadoop",
                "SparkSQL",
                "Bigdata technologies",
                "UNIX shell scripting"
            ],
            "primary": [
                "Data Science concepts",
                "Oracle",
                "Java",
                "Python",
                "Kafka",
                "HDFS",
                "Airflow",
                "Elastic Search",
                "AWS Services",
                "GitHub",
                "Jenkins"
            ],
            "secondary": [
                "Confluence",
                "Jira",
                "Athena",
                "EMR",
                "Redshift",
                "Kinesis",
                "Aurora",
                "RDS",
                "S3",
                "AdTech/MarTech platforms"
            ],
            "all": [
                "Snowflake",
                "Hadoop",
                "SparkSQL",
                "Bigdata technologies",
                "UNIX shell scripting",
                "Data Science concepts",
                "Oracle",
                "Java",
                "Python",
                "Kafka",
                "HDFS",
                "Airflow",
                "Elastic Search",
                "AWS Services",
                "GitHub",
                "Jenkins",
                "Confluence",
                "Jira",
                "Athena",
                "EMR",
                "Redshift",
                "Kinesis",
                "Aurora",
                "RDS",
                "S3",
                "AdTech/MarTech platforms"
            ]
        },
        "job_type": [
            "onsite"
        ],
        "contact_person": "Akshat Kumar",
        "email": "akshat@tanishasystems.com",
        "jd": "Greetings..!! My name is Akshat, and I am a Technical Recruiter at Tanisha Systems Inc. Tanisha Systems Inc is a global contingency staffing firm servicing. We have an excellent job opportunity with one of our clients. Role: Analytics - Snowflake and Hadoop - Senior RoleLocation : Wilmington, DE (Onsite- 3 days per week)Type: ContractExp: 10+ yrsJob Description:Job responsibilityData domain expert and drive to know everything about the data on the platformCreate Functional and Technical Specifications, Epics and User Stories, Process Flows, Data Analysis, MappingDocuments, Implementation Plan, Agile artifactsMigration from Hadoop to AWS using Pipelines, EMRDevelop, enhance and test new/existing interfaces. The candidate will be part of existing agile team and will work on developing, enhancing ETL pipelines, design solutions,Handle Dev Ops effort in terms of CICD, Scanning, Code, Performance testing and Test coverageIdentify, analyze, and interpret trends or patterns in complex data sets and transforming existing ETL logic into Hadoop PlatformInnovate new ways of managing, transforming and validating dataEstablish and enforce guidelines to ensure consistency, quality and completeness of data assets Apply quality assurance best practices to all work products Experience of working in a development teams, using agile techniques and Object-Oriented development and scripting languages, is preferred.Adds to team culture of diversity, equity, inclusion, and respectRequired qualifications, capabilities, and skills10+ years of Database experience Knowledge of application. data, and infrastructure architecture disciplines\u2018Strong experience with documentation and structuring information in tools lke Confluence and JiraExperience in SparkSQLimapala and Bigdata technologiesFamiliar with Data Science concepts and applying them to analyze large volumes of dataComfortable with data concepts: Oracle, Java, Python. Spark, Kafka, HDFS, Airflow, Elastic Search.Working proficiency in SDLC CV/CO Execution (GitHub, Jenkins. SNOR Spinnaker. AIM etc)Experience in services like Lambda EC2Experience in real time streaming dataStrong Experience with UNIX shell srpting is mustExperience with relational database environment (Oracle, Teradata, SQL Server. etc) leveraging databases, tables/views,stored procedures, agent jobs, etc. with strong analytical skills withthe ability to collect. organize. analyze, anddisseminate significant amounts of information with attention to detail and accuracy\u2018Good understanding of Change management processBS. or MS. in computer science, information systems, math, business, or engineeringPreferred qualifications, capabilities, and skillsMinimum 2+ Experience with AWS Services like Lambda EC2Experience in Athena, EMR Redshift Giue Kinesis AuroraRDSS3Knowledge in one or more modem programming languages lke Java or Python is a plus[AWS Cloud Practitioner certification a plus for applicant and expected upon joining teamExperience working on AdTech/MarTech platforms is a plus",
        "source": "Email",
        "date_posted": "2024-10-02 08:39:02-05:00",
        "unique_id": "1924d7420bd7b6c1",
        "emp_type": [
            "contract",
            "third party"
        ],
        "tag": "AWS Data Engineer"
    }
]