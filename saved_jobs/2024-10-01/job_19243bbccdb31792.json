[
    {
        "company": "SPAR Information Systems",
        "job_title": "GCP Data Engineer",
        "location": "Sunnyvale, CA, USA",
        "full_location": {
            "city": "Sunnyvale",
            "state": "CA",
            "country": "USA"
        },
        "job_details": {
            "employment_type": [
                "contract",
                "third party"
            ],
            "job_code": "",
            "experience_required": "5+ years",
            "degree_required": "Bachelor's Degree in computer science or equivalent experience",
            "visa_sponsorship": "Not specified",
            "notice_period": "Not specified",
            "duration": "Long Term Contract",
            "rate": "Not specified"
        },
        "skills": {
            "core": [
                "GCP",
                "Hadoop",
                "Spark",
                "Scala",
                "ETL Process",
                "Data Pipeline"
            ],
            "primary": [
                "Apache Airflow",
                "Apache Hive",
                "Apache Kafka",
                "Python",
                "Java"
            ],
            "secondary": [
                "Perl",
                "Shell",
                "Gitflow",
                "Atlassian products"
            ],
            "all": [
                "GCP",
                "Hadoop",
                "Spark",
                "Scala",
                "ETL Process",
                "Data Pipeline",
                "Apache Airflow",
                "Apache Hive",
                "Apache Kafka",
                "Python",
                "Java",
                "Perl",
                "Shell",
                "Gitflow",
                "Atlassian products"
            ]
        },
        "job_type": [
            "hybrid"
        ],
        "contact_person": "Rahul Kumar",
        "email": "rahul.k@sparinfosys.com",
        "jd": "Hello Folks, (Prefer local to California profiles & who can share local CA state ID/ DL copy) - Note it AND Must have strong exp in GCP, Hadoop, Spark, Scala skillsHope you all are doing good.\n\nPlease go through the Job description and let me know your interest.\n\nTitle: GCP Data Engineer\nWork Location: Sunnyvale, CA & Bentonville, AR (Hybrid)\nDuration: Long Term Contract\n\nMust Have Skills \u2013\nHadoop- 8+ Yrs of Exp\nSpark - 8+ Yrs of Exp\nScala - 5+ Yrs of Exp\nGCP - 5+ Yrs of Exp\nETL Process / Data Pipeline experience \u2013 8+ Yrs of Exp\n\nJob Description:\nResponsibilities:\nAs a Senior Data Engineer, you will\n\u2022 Design and develop big data applications using the latest open source technologies.\n\u2022 Desired working in offshore model and Managed outcome\n\u2022 Develop logical and physical data models for big data platforms.\n\u2022 Automate workflows using Apache Airflow.\n\u2022 Create data pipelines using Apache Hive, Apache Spark, Apache Kafka.\n\u2022 Provide ongoing maintenance and enhancements to existing systems and participate in rotational on-call support.\n\u2022 Learn our business domain and technology infrastructure quickly and share your knowledge freely and actively with others in the team.\n\u2022 Mentor junior engineers on the team\n\u2022 Lead daily standups and design reviews\n\u2022 Groom and prioritize backlog using JIRA\n\u2022 Act as the point of contact for your assigned business domain\n\nRequirements:\nGCP Experience\n\u2022 2+ years of recent GCP experience\n\u2022 Experience building data pipelines in GCP\n\u2022 GCP Dataproc, GCS & BIGQuery experience\n\u2022 5+ years of hands-on experience with developing data warehouse solutions and data products.\n\u2022 5+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive or Spark, Airflow or a workflow orchestration solution are required\n\u2022 2+ years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms.\n\u2022 Experience with programming languages: Python, Java, Scala, etc.\n\u2022 Experience with scripting languages: Perl, Shell, etc.\n\u2022 Practice working with, processing, and managing large data sets (multi TB/PB scale).\n\u2022 Exposure to test driven development and automated testing frameworks.\n\u2022 Background in Scrum/Agile development methodologies.\n\u2022 Capable of delivering on multiple competing priorities with little supervision.\n\u2022 Excellent verbal and written communication skills.\n\u2022 Bachelor's Degree in computer science or equivalent experience.\n\nThe most successful candidates will also have experience in the following:\n\u2022 Gitflow\n\u2022 Atlassian products \u2013 BitBucket, JIRA, Confluence etc.",
        "source": "Email",
        "date_posted": "2024-09-30 10:18:52-05:00",
        "unique_id": "19243bbccdb31792",
        "emp_type": [
            "contract",
            "third party"
        ],
        "tag": "GCP Data Engineer"
    }
]