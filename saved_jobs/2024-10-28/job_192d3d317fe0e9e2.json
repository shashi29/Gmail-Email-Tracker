[
    {
        "company": "Veridian",
        "job_title": "Databricks Engineer",
        "location": "New York City, NY, USA",
        "full_location": {
            "city": "New York City",
            "state": "NY",
            "country": "USA"
        },
        "job_details": {
            "employment_type": [
                "third party"
            ],
            "job_code": "",
            "experience_required": "5+ years",
            "degree_required": "Bachelor's degree in Computer Science, Engineering, or related field, or equivalent work experience",
            "visa_sponsorship": "Not specified",
            "notice_period": "Not specified",
            "duration": "Not specified",
            "rate": "Not specified"
        },
        "skills": {
            "core": [
                "Databricks",
                "Spark",
                "SQL",
                "Pyspark",
                "Azure"
            ],
            "primary": [
                "Data Engineering",
                "ETL",
                "Data Integration",
                "Data Warehouse",
                "Data Lake"
            ],
            "secondary": [
                "Kafka",
                "Hadoop",
                "Hive",
                "Data Governance",
                "Data Quality"
            ],
            "all": [
                "Databricks",
                "Spark",
                "SQL",
                "Pyspark",
                "Azure",
                "Data Engineering",
                "ETL",
                "Data Integration",
                "Data Warehouse",
                "Data Lake",
                "Kafka",
                "Hadoop",
                "Hive",
                "Data Governance",
                "Data Quality"
            ]
        },
        "job_type": [],
        "contact_person": "Madhavi",
        "email": "madhavi@veridiants.com",
        "jd": "From: madhavi, veridian madhavi@veridiants.com Reply to: madhavi@veridiants.com Strong knowledge on databricks architecture and toolsHave experience of task and wf jobs creations in databricks.Deep understanding of distributed computing and how to use spark for dataprocessing.SQL and pyspark : strong command over querying databases and proficiency in pyspark.Cloud platform: Preferred Azure for databricks deployment.ResponsibilitiesDesign, develop, and maintain data pipelines using Databricks and Spark, and other cloud technologies as neededOptimize data pipelines for performance, scalability, and reliabilityEnsure data quality and integrity throughout the data lifecycleCollaborate with data scientists, analysts, and other stakeholders to understand and meet their data needsTroubleshoot and resolve data-related issues, and provide root cause analysis and recommendationsDocument data pipeline specifications, requirements, and enhancements, and communicate them effectively to the team and managementCreate new data validation methods and data analysis tools, and share best practices and learnings with the data engineering communityImplement ETL processes and data warehouse solutions, and ensure compliance with data governance and security policiesQualificationsBachelor's degree in Computer Science, Engineering, or related field, or equivalent work experience5+ years of experience in data engineering with Databricks and SparkProficient in SQL and Python and PysparkExperience with Azure Databricks Medallion Architecture with DLT, IcebergFinancial/Corporate Banking context would be a plusExperience with data integration and ETL tools, such as Azure Data Factory Experience with Azure cloud platform and servicesExperience with data warehouse and data lake concepts and architecturesGood to have experience with big data technologies, such as Kafka, Hadoop, Hive, etcStrong analytical and problem-solving skillsExcellent communication and teamwork skills Requirements:Strong knowledge on data bricks architecture and tools.Have experience of task and wf jobs creations in data bricks.Deep understanding of distributed computing and how to use spark for data processing.SQL and Pyspark - strong command over querying databases and proficiency in Pyspark.Cloud platform: Preferred Azure for data bricks deployment.",
        "source": "Email",
        "date_posted": "2024-10-28 10:16:19-05:00",
        "unique_id": "192d3d317fe0e9e2",
        "emp_type": [
            "third party"
        ],
        "tag": "Azure Data Engineer"
    }
]