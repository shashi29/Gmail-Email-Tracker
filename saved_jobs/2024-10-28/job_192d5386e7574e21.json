[
    {
        "company": "Flagstar",
        "job_title": "Senior Data Engineer",
        "location": "Troy, MI, USA",
        "full_location": {
            "city": "Troy",
            "state": "MI",
            "country": "USA"
        },
        "job_details": {
            "employment_type": [
                "full-time",
                "third party"
            ],
            "experience_required": "10+ years",
            "degree_required": "Bachelor's in Computer Science, Mathematics or related field",
            "visa_sponsorship": "No visa sponsorship",
            "notice_period": "Not specified",
            "duration": "12 months",
            "rate": "Not specified"
        },
        "skills": {
            "core": [
                "ETL",
                "Business Intelligence",
                "Data Warehouse",
                "Data Integration",
                "SQL"
            ],
            "primary": [
                "Snowflake",
                "Oracle",
                "IBM Cognos",
                "Power BI",
                "DataStage",
                "Informatica",
                "Matillion",
                "FiveTran",
                "Talend",
                "Dbt",
                "AWS",
                "Data Modeling"
            ],
            "secondary": [
                "Agile",
                "SCRUM",
                "Waterfall",
                "AI/ML Engineering",
                "Predictive Analytics",
                "Prescriptive Analytics",
                "Data Mesh",
                "Data as a Service"
            ],
            "all": [
                "ETL",
                "Business Intelligence",
                "Data Warehouse",
                "Data Integration",
                "SQL",
                "Snowflake",
                "Oracle",
                "IBM Cognos",
                "Power BI",
                "DataStage",
                "Informatica",
                "Matillion",
                "FiveTran",
                "Talend",
                "Dbt",
                "AWS",
                "Data Modeling",
                "Agile",
                "SCRUM",
                "Waterfall",
                "AI/ML Engineering",
                "Predictive Analytics",
                "Prescriptive Analytics",
                "Data Mesh",
                "Data as a Service"
            ]
        },
        "job_type": [
            "hybrid"
        ],
        "contact_person": "Raj",
        "email": "raj.s@techgene.com",
        "jd": "From: Raj, Techgene raj.s@techgene.com Reply to: raj.s@techgene.com I tried to reach you for the below position Senior Data Engineer (10+ years) and Candidates must be LOCAL to the TROY, MI I hope you are well. I am (Raj) with Techgene Solutions LLC. We\u2019re Senior Data Engineer (10+ years)). I think your experience is a great fit for this role. If you\u2019re interested in learning more, I\u2019d love to connect with you. Please review the Job description below and let me know if you are comfortable. I look forward to hearing from you soon. Thank you! Please share your profiles to raj.s@techgene.com or you can reach me at 972-580-0247 Ext 253 CHECKPOINT Full Legal Name Contact Number Email ID Date of Birth (MM/DD) Last 4 Digit SSN Current Location with Zip Code Two LinkedIn references from their recent two projects Work Authorization/Visa Status Passport Number Corporation Name Open to relocate OR Travel LinkedIn Total Years of IT Experience Education DetailsUniversity, year: US Experience Senior Data Engineer (10+ years) Experience Required**: - Extensive experience with ETL - Business Intelligence (Cognos or Power BI) - Data Warehouse experienceCandidate Requirements**: - Long project history/good tenure - Excellent communication skills - State-issued ID (not bills) showing local residency Required Location: Hybrid/ Candidates must be LOCAL to the TROY, MI / 3 days a week.duration: 12 monthInterview Required: VideoAny Visa\u2019s Accepted: No Opt. Sub-contracting: Yes Candidates must be LOCAL to the TROY, MI area and COMMUTE into the office THREE TIMES A WEEK. NO RELOCATION CONSIDERED. *** Please send candidates even if they are over the target rate. The Client is flexible. *** PLEASE Only send me candidates in the TROY, MI area Open to Hybrid. *** Please make sure that each submittal includes:1. Driver\u2019s license or State ID2. Link to the candidates LinkedIn account.3. Below submittal Format *** Candidate Must Have\u2019s on a resume and for submittal: 1. How many years working with: Sr. Data Engineer2. How many years working with: ETL3. How many years working with: Business Intelligence4. How many years working with: Data Warehouse5. How many years working with: Local to Troy MI Submission format :\u00b7 Full Name:\u00b7 Rate: \u00b7 Location: \u00b7 Availability to Interview: One Day\u2019s notice\u00b7 Availability to Start: \u00b7 Email Address: \u00b7 Phone Number: \u00b7 Visa Status:\u00b7 Education - College/Year of graduation:\u00b7 Link to LinkedIn? \u00b7 Certifications (Please list)? Job Description: Title Sr Data Engineer Location Flagstar, Troy, MI Job Summary The Sr. Data Engineer is responsible in understanding and supporting the businesses through the design, development, and execution of Extract, Transform, and Load (ELT/ETL), data integration, and data analytics processes across the enterprise. He/She will stay on top of tech trends, experiment with and learn new technologies, contribute to the growth of data organization, participate in internal & external technology communities, and mentor other members of the team. Provide technical leadership at every stage of the data engineering lifecycle, from designing data platforms, data pipelines, data stores, and gathering, importing, wrangling, querying, and analyzing data. The Sr data engineer will work closely with various customers including their immediate project teams, business domain experts and other technical staff members. Work daily within a project team environment, taking direction from project management and technical leaders. Responsible for design, development, administration, support, and maintenance of the Snowflake Platform and Oracle Platform. Participates in the full systems life cycle and cloud data lake/data warehouse design and build including recommendation of code development, integration with data marketplace or reuse and buy versus build solutions. Job Responsibilities: \u00b7 Technical Leadership \u2013Lead data integration across the enterprise thru design, build and implementation of large scale, high volume, high performance data pipelines for both on-prem and cloud data lake and data warehouses. Lead the development and documentation of technical best practices for ELT/ETL activities. Also, oversee a program inception to build a new product if needed. \u00b7 Solution Design \u2013 Lead the design of technical solution including code, scripts, data pipelines, processes/procedures for integration of data lake and data warehouse solutions in an operative IT environment.\u00b7 Code Development \u2013 Ensures data engineering activities are aligned with scope, schedule, priority and business objectives. Oversees code development, unit and performance testing activities. Responsible to code and lead the team to implement the solution.\u00b7 Testing \u2013 Leads validation efforts by verifying the data at various middle stages that are being used between source and destination and assisting others in validating the solution performs as expected. Meets or exceeds all operational readiness requirements (e.g., operations engineering, performance, and risk management). \u00b7 Ensure compliance with applicable federal, state and local laws and regulations. Complete all required compliance training. Maintain knowledge of and adhere to Flagstar's internal compliance policies and procedures. Take responsibility to keep up to date with changing regulations and policies. Job Requirements: \u00b7 High School Diploma, GED, or foreign equivalent required.\u00b7 Bachelor's in Computer Science, Mathematics or related field + 7 years of development experience preferred, or 10 years comparable work experience required.\u00b7 10 years of experience designing, developing, testing, and implementing Extract, Transform and Load (ELT/ETL) solutions using enterprise ELT/ETL\u00b7 15 years of comparable work experience.\u00b7 10 years of experience developing and implementing data integration, data lake and data warehouse solutions in an on-premise and cloud environment.\u00b7 5 years of experience working with Business Intelligence tools (IBM Cognos is preferred), Power BI and Alteryx.\u00b7 7 years of experience working with API\u2019s, data as a service, data marketplace and data mesh.\u00b7 10 years of experience with various Software Development Life Cycle methods such as Agile, SCRUM, Waterfall, etc.\u00b7 3-year experience in 100+ TB data environment.\u00b7 Proven experience developing and maintaining data pipelines and ETL jobs using IBM DataStage, Informatica, Matillion, FiveTran, Talend or Dbt\u00b7 Knowledge of AWS cloud services such as S3, EMR, Lambda, Glue, Sage Maker, Redshift & Athena and/or Snowflake.\u00b7 Experienced in data modelling for self-service business intelligence, advanced analytics, and user application.\u00b7 Experience with Data Science including AI/ML Engineering, ML framework/pipeline build and predictive/prescriptive analytics on Aws Sagemaker.\u00b7 Experience with migrating, architecting, designing, building and implementing cloud data lake, data warehouses (cloud/on-prem), data mesh, data as a service, and cloud data marketplace.\u00b7 Ability to communicate complex technical concepts by adjusting messaging to the audience: business partners, IT peers, external stakeholders, etc.\u00b7 Proven ability to design and build technical solutions using applicable technologies; ability to demonstrate exceptional data engineering skills. \u00b7 Ability to prioritize work by dividing time, attention and effort between current project workload and on-going day to day activities.\u00b7 Demonstrates strength in adapting to change in processes, procedures and priorities.\u00b7 Proven ability to establish a high level of trust and confidence in both the business and IT communities.\u00b7 Strong teamwork and interpersonal skills at all management levels.\u00b7 Proven ability to manage to a project budget.\u00b7 Experience applying agile practices to solution delivery.\u00b7 Must be team-oriented and have excellent oral and written communication skills.\u00b7 Strong analytic and problem-solving skills.\u00b7 Good organizational and time-management skills.\u00b7 Experience in Strategic Thinking and Solutioning.\u00b7 Must be a self-starter to understand existing bottlenecks and come up with innovative solution.\u00b7 Demonstrated ability to work with key stakeholders outside the project to understand requirements/resolve issues.\u00b7 Experience with data model design, writing complex SQL queries, etc., and should have a good understanding of BI/DWH principles.\u00b7 Expertise in Relational Database Management System, Data Mart and Data Warehouse design.\u00b7 Expert-level SQL development skills in a multi-tier environment.\u00b7 Expertise in flat file formats, XML within PL/SQL, and file format conversion.\u00b7 Strong understanding of SDLC and Agile Methodologies.\u00b7 Strong understanding of model driven development. \u00b7 Strong understanding of ETL best practices. \u00b7 Proven strength in interpreting customer business needs and translating them into application and operational requirements. \u00b7 Strong problem-solving skills and analytic skills with proven strength in applying root cause analysis.",
        "source": "Email",
        "date_posted": "2024-10-28 16:46:38-05:00",
        "unique_id": "192d5386e7574e21",
        "emp_type": [
            "full-time",
            "third party"
        ],
        "tag": "AWS Data Engineer"
    }
]