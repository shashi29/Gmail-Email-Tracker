[
    {
        "company": "SPAR Information Systems",
        "job_title": "GCP Data Engineer",
        "location": "Sunnyvale, CA, USA",
        "full_location": {
            "city": "Sunnyvale",
            "state": "CA",
            "country": "USA"
        },
        "job_details": {
            "employment_type": [
                "contract"
            ],
            "job_code": "",
            "experience_required": "8+ Yrs for Hadoop and Spark, 5+ Yrs for Scala and GCP",
            "degree_required": "Bachelor's Degree in computer science or equivalent experience",
            "visa_sponsorship": "",
            "notice_period": "",
            "duration": "Long Term Contract",
            "rate": ""
        },
        "skills": {
            "core": [
                "GCP",
                "Hadoop",
                "Spark",
                "Scala",
                "ETL Process",
                "Data Pipeline"
            ],
            "primary": [
                "GCP",
                "Hadoop",
                "Spark"
            ],
            "secondary": [
                "Scala",
                "ETL Process",
                "Data Pipeline"
            ],
            "all": [
                "GCP",
                "Hadoop",
                "Spark",
                "Scala",
                "ETL Process",
                "Data Pipeline",
                "Python",
                "Java",
                "Perl",
                "Shell",
                "Apache Airflow",
                "Apache Hive",
                "Apache Kafka"
            ],
            "with_experience": [
                "GCP",
                "Hadoop",
                "Spark",
                "Scala",
                "ETL Process",
                "Data Pipeline"
            ]
        },
        "job_type": [
            "hybrid"
        ],
        "contact_person": "Rahul Kumar",
        "email": "rahul.k@sparinfosys.com",
        "jd": "Hello Folks, (Prefer local to California profiles & who can share local CA state ID/ DL copy) - Note it AND Must have strong exp in GCP, Hadoop, Spark, Scala skills Hope you all are doing good. Please go through the Job description and let me know your interest. Title: GCP Data Engineer Work Location: Sunnyvale, CA & Bentonville, AR (Hybrid) Duration: Long Term Contract Must Have Skills \u2013 Hadoop- 8+ Yrs of Exp Spark - 8+ Yrs of Exp - Scala - 5+ Yrs of Exp GCP - 5+ Yrs of Exp ETL Process / Data Pipeline experience \u2013 8+ Yrs of Exp \u2013 Job Description: Responsibilities: As a Senior Data Engineer, you will \u2022 Design and develop big data applications using the latest open source technologies. \u2022 Desired working in offshore model and Managed outcome \u2022 Develop logical and physical data models for big data platforms. \u2022 Automate workflows using Apache Airflow. \u2022 Create data pipelines using Apache Hive, Apache Spark, Apache Kafka. \u2022 Provide ongoing maintenance and enhancements to existing systems and participate in rotational on-call support. \u2022 Learn our business domain and technology infrastructure quickly and share your knowledge freely and actively with others in the team. \u2022 Mentor junior engineers on the team \u2022 Lead daily standups and design reviews \u2022 Groom and prioritize backlog using JIRA \u2022 Act as the point of contact for your assigned business domain Requirements: GCP Experience \u2022 2+ years of recent GCP experience \u2022 Experience building data pipelines in GCP \u2022 GCP Dataproc, GCS & BIGQuery experience \u2022 5+ years of hands-on experience with developing data warehouse solutions and data products. \u2022 5+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive or Spark, Airflow or a workflow orchestration solution are required \u2022 2+ years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms. \u2022 Experience with programming languages: Python, Java, Scala, etc. \u2022 Experience with scripting languages: Perl, Shell, etc. \u2022 Practice working with, processing, and managing large data sets (multi TB/PB scale). \u2022 Exposure to test driven development and automated testing frameworks. \u2022 Background in Scrum/Agile development methodologies. \u2022 Capable of delivering on multiple competing priorities with little supervision. \u2022 Excellent verbal and written communication skills. \u2022 Bachelor's Degree in computer science or equivalent experience. The most successful candidates will also have experience in the following: \u2022 Gitflow \u2022 Atlassian products \u2013 BitBucket, JIRA, Confluence etc.",
        "source": "Email",
        "date_posted": "2024-09-30 10:18:52-05:00",
        "unique_id": "19243bbccdb31792",
        "tag": "GCP Data Engineer"
    }
]